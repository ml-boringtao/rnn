{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.constraints import maxnorm\n",
    "from keras import regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, SeparableConv2D\n",
    "from keras.layers import concatenate, add, Lambda\n",
    "from keras.layers import LSTM\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from keras.applications import imagenet_utils, Xception\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras.backend as K\n",
    "\n",
    "import numpy as np \n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import h5py\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from helpers import TrainingMonitor\n",
    "from helpers import Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_path = \"../output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "data = pickle.load(open('../input/datasets/UCF-101-hdf5/full_sequence_rgbmean.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_split, val_split = 0.7, 0.15\n",
    "random.shuffle(data)\n",
    "\n",
    "train_len = int(train_split * len(data))\n",
    "train_val_len = int((train_split + val_split) * len(data))\n",
    "train = data[:train_len]\n",
    "val = data[train_len:train_val_len]\n",
    "test = data[train_val_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train, y_train = np.array([t[\"imgs\"] for t in train]), [t[\"label\"] for t in train]\n",
    "x_val, y_val = np.array([t[\"imgs\"] for t in val]), [t[\"label\"] for t in val]\n",
    "x_test, y_test = np.array([t[\"imgs\"] for t in test]), [t[\"label\"] for t in test]\n",
    "\n",
    "x_train = pad_sequences(x_train, maxlen=1, truncating=\"post\")\n",
    "x_val = pad_sequences(x_val, maxlen=1, truncating=\"post\")\n",
    "x_test = pad_sequences(x_test, maxlen=1, truncating=\"post\")\n",
    "\n",
    "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 60*80*3))\n",
    "x_val = x_val.reshape((x_val.shape[0], x_val.shape[1], 60*80*3))\n",
    "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 60*80*3))\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(y_train)\n",
    "y_val = lb.fit_transform(y_val)\n",
    "y_test = lb.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 1, 14400)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = y_train.shape[1]\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, input_shape=(x_train.shape[1:])))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dense(num_classes)) \n",
    "model.add(Activation(\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 140 samples, validate on 30 samples\n",
      "Epoch 1/5\n",
      "140/140 [==============================] - 3s 18ms/step - loss: 0.6902 - acc: 0.6857 - val_loss: 0.6802 - val_acc: 0.8750\n",
      "Epoch 2/5\n",
      "140/140 [==============================] - 0s 609us/step - loss: 0.6772 - acc: 0.8750 - val_loss: 0.6637 - val_acc: 0.8750\n",
      "Epoch 3/5\n",
      "140/140 [==============================] - 0s 587us/step - loss: 0.6592 - acc: 0.8750 - val_loss: 0.6397 - val_acc: 0.8750\n",
      "Epoch 4/5\n",
      "140/140 [==============================] - 0s 594us/step - loss: 0.6331 - acc: 0.8750 - val_loss: 0.6059 - val_acc: 0.8750\n",
      "Epoch 5/5\n",
      "140/140 [==============================] - 0s 573us/step - loss: 0.5965 - acc: 0.8750 - val_loss: 0.5604 - val_acc: 0.8750\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "            batch_size=64,\n",
    "            epochs=5,\n",
    "            validation_data=(x_val, y_val),\n",
    "            shuffle=\"batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 87.50%; Val: 87.50%; Test: 87.50%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Train: %.2f%%; Val: %.2f%%; Test: %.2f%%\" % \n",
    "      (np.max(history.history['acc'])*100, np.max(history.history['val_acc'])*100, scores[1]*100)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, stateful=True, batch_input_shape=(5, 1, 14400))) \n",
    "model.add(Dense(num_classes)) \n",
    "model.add(Activation(\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "140/140 [==============================] - 1s 6ms/step - loss: 0.4639 - acc: 0.8286\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3882 - acc: 0.8750\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3774 - acc: 0.8750\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3739 - acc: 0.8750\n",
      "Epoch 1/1\n",
      "140/140 [==============================] - 1s 4ms/step - loss: 0.3721 - acc: 0.8750\n"
     ]
    }
   ],
   "source": [
    "for i in range(5): \n",
    "    model.fit(x_train, y_train, epochs=1, batch_size=5)\n",
    "    model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
